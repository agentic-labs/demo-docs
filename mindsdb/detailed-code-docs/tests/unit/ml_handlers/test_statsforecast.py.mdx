---
title: "test_statsforecast.py"
---

## High-level description
This file contains unit tests for the StatsForecast handler in MindsDB. It tests various functionalities of the handler, including model selection, grouped predictions, hierarchical forecasting, and integration with the MindsDB SQL interface.

## Code Structure
The file defines a main test class `TestStatsForecast` that inherits from `BaseExecutorTest`. This class contains multiple test methods that cover different aspects of the StatsForecast handler. Additionally, there's a standalone function `test_choose_model` that tests the model selection process.

## Symbols

### `test_choose_model()`
#### Description
This function tests the `choose_model` function from the StatsForecast handler.

#### Internal Logic
1. Creates a sample dataset using `AirPassengersDF`.
2. Calls `get_insample_cv_results` to perform cross-validation.
3. Calls `choose_model` with the results.
4. Asserts that the chosen model is "AutoTheta".

### `class TestStatsForecast(BaseExecutorTest)`
#### Description
This class contains the main test suite for the StatsForecast handler.

#### Internal Logic
The class sets up a mock database and handler for testing. It includes several test methods:

1. `test_grouped`: Tests grouped predictions.
2. `test_model_choice`: Tests model selection based on user input.
3. `test_auto_model_selection`: Tests automatic model selection.
4. `test_hierarchical`: Tests hierarchical forecasting.

Each test method follows a similar pattern:
1. Set up a mock database and data.
2. Create a model using SQL commands.
3. Wait for the predictor to complete.
4. Run predictions using SQL joins.
5. Assert the results match expected outputs.

### `wait_predictor(self, project, name)`
#### Description
A helper method to wait for a predictor to complete.

#### Inputs
- `project`: The project name
- `name`: The predictor name

#### Internal Logic
Polls the database every 0.5 seconds for up to 100 seconds, checking if the predictor status is "complete" or "error".

### `run_sql(self, sql)`
#### Description
A helper method to execute SQL commands.

#### Inputs
- `sql`: The SQL command to execute

#### Outputs
Returns the result of the SQL execution as a DataFrame.

## Dependencies
- `unittest.mock`: For patching and mocking
- `numpy`: For numerical operations
- `pandas`: For data manipulation
- `pytest`: For test assertions
- `statsforecast`: For time series forecasting models
- `mindsdb_sql`: For SQL parsing
- Various MindsDB internal modules

## Error Handling
The tests use `pytest.raises` to check for expected exceptions in certain scenarios.

## API/Interface Reference
The tests interact with the MindsDB SQL interface, demonstrating how to:
- Create models
- Make predictions
- Describe model features and properties

These tests serve as both a verification of the StatsForecast handler's functionality and a demonstration of how to use it within the MindsDB ecosystem.