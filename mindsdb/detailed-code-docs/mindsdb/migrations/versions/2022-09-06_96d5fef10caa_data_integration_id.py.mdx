---
title: "2022-09-06_96d5fef10caa_data_integration_id.py"
---

## High-level description
This migration script adds a new column `data_integration_id` to the `predictor` table, updates existing data, and establishes a foreign key relationship. It also ensures the 'lightwood' integration exists and updates the `integration_id` column for all predictors.

## Code Structure
The code consists of two main functions: `upgrade()` and `downgrade()`. These functions handle the forward and backward migration processes respectively, using SQLAlchemy and Alembic operations.

## Symbols

### upgrade()
#### Description
This function performs the database schema upgrade by adding a new column, inserting data, and updating existing records.

#### Internal Logic
1. Adds a new column `data_integration_id` to the `predictor` table.
2. Checks if the 'lightwood' integration exists, and inserts it if not.
3. Updates `data_integration_id` with existing `integration_id` values.
4. Sets `integration_id` for all predictors to the 'lightwood' integration.
5. Makes `integration_id` non-nullable.
6. Creates a foreign key constraint for `data_integration_id`.

### downgrade()
#### Description
This function reverts the changes made by the `upgrade()` function.

#### Internal Logic
1. Updates `integration_id` with `data_integration_id` values.
2. Removes the foreign key constraint for `data_integration_id`.
3. Makes `integration_id` nullable.
4. Drops the `data_integration_id` column.

## Dependencies
| Dependency | Purpose |
|:-----------|:--------|
| alembic | Database migration tool |
| sqlalchemy | SQL toolkit and ORM |
| mindsdb.interfaces.storage.db | MindsDB storage interface |

## Error Handling
The script does not implement explicit error handling. It relies on the default error handling provided by Alembic and SQLAlchemy.

## Performance Considerations
The script uses batch operations (`batch_alter_table`) for table alterations, which can improve performance for certain database backends. However, the data updates are performed using raw SQL queries, which might have performance implications for large datasets.