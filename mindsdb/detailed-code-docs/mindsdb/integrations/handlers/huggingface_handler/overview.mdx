---
title: "Overview"
---

## High-level description
This directory contains the Hugging Face integration handler for MindsDB. It allows users to leverage Hugging Face's Transformers library for various natural language processing (NLP) tasks within the MindsDB ecosystem. The handler supports loading pre-trained models, fine-tuning them on custom data, and using them for predictions.

## What does it do?
The Hugging Face handler enables MindsDB users to:
1. Load pre-trained models from the Hugging Face Model Hub
2. Fine-tune models on custom datasets for specific NLP tasks
3. Use models for predictions on new data
4. Perform various NLP tasks such as text classification, text generation, translation, summarization, and more

The handler acts as a bridge between MindsDB's SQL-like interface and Hugging Face's Transformers library, allowing users to interact with state-of-the-art NLP models using familiar SQL commands.

## Entry points
The main entry point for this handler is the `HuggingFaceHandler` class defined in `huggingface_handler.py`. This class implements the core functionality for interacting with Hugging Face models, including:

- Creating and validating model configurations
- Loading and saving models
- Making predictions
- Fine-tuning models on custom data

The handler uses the `transformers` library to create pipelines for different NLP tasks and interacts with MindsDB's storage mechanisms to persist model artifacts.

## Key Files
1. `huggingface_handler.py`: Contains the `HuggingFaceHandler` class, which is the core of the integration.
2. `finetune.py`: Implements fine-tuning functions for different NLP tasks.
3. `settings.py`: Defines a mapping between NLP tasks and their corresponding fine-tuning functions.
4. `__init__.py`: Exports the handler and defines metadata for the integration.
5. `__about__.py`: Contains package metadata such as version and description.

## Dependencies
The handler relies on several external libraries:
- `transformers`: For loading and using Hugging Face models
- `datasets`: For handling and processing datasets
- `evaluate`: For loading metrics for model evaluation
- `nltk`: For text processing tasks
- `numpy`: For numerical operations
- `pandas`: For data manipulation and analysis
- `huggingface_hub`: For interacting with the Hugging Face Model Hub

## Configuration
The handler can be configured when creating an AI engine in MindsDB. Users can specify:
- The Hugging Face API key
- The model name to use
- The specific NLP task to perform
- Input and target columns for the data
- Labels for classification tasks

Example configuration:
```sql
CREATE ML_ENGINE huggingface_engine
FROM huggingface
USING huggingface_api_api_key = 'hf_xxx';

CREATE MODEL huggingface_model
PREDICT target_column
USING
      engine = 'huggingface_engine',
      model_name = 'hf_hub_model_name',
      task = 'task_name',
      input_column = 'column_name',
      labels = ['label 1', 'label 2'];
```

The handler supports various NLP tasks, including text classification, text generation, translation, summarization, and more. Each task may have specific configuration options and requirements.

In summary, this Hugging Face handler provides a powerful integration that allows MindsDB users to leverage state-of-the-art NLP models and techniques within their existing data workflows, bridging the gap between SQL-based data analysis and advanced machine learning capabilities.