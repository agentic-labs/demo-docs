---
title: "Overview"
---

## High-level description
This directory contains the implementation of the TPOT (Tree-based Pipeline Optimization Tool) handler for MindsDB. TPOT is an automated machine learning tool that optimizes machine learning pipelines using genetic programming. The integration allows MindsDB users to leverage TPOT's capabilities for automated model selection and hyperparameter tuning within their MindsDB workflows.

## What does it do?
The TPOT handler automates the process of building and optimizing machine learning models within MindsDB. It performs the following key functions:

1. Automatically selects appropriate machine learning algorithms and preprocessors for a given dataset.
2. Optimizes hyperparameters for the selected algorithms using genetic programming.
3. Constructs and evaluates machine learning pipelines to find the best performing model.
4. Handles both classification and regression tasks.
5. Manages categorical data encoding automatically.
6. Provides an interface for creating models and making predictions using TPOT within MindsDB.

This integration is particularly useful for users who want to quickly generate high-quality predictive models without extensive manual feature engineering or hyperparameter tuning.

## Key Files
1. `tpot_handler.py`: This is the core file implementing the `TPOTHandler` class. It contains the logic for creating TPOT models, training them, and making predictions.

2. `__init__.py`: This file sets up the TPOT handler, handling imports and defining metadata about the handler.

3. `__about__.py`: Contains metadata information for the TPOT handler, including version, description, and author details.

4. `example.md`: Provides a tutorial on how to use the TPOT handler within MindsDB, including SQL commands for creating models and making predictions.

## Dependencies
The TPOT handler relies on the following main external libraries:

1. TPOT (Tree-based Pipeline Optimization Tool): Used for automated machine learning and pipeline optimization.
   - Version: Not specified in the provided files.
   - Chosen for its ability to automate the machine learning workflow and optimize model performance.

2. pandas: Used for data manipulation and analysis.
   - Version: Not specified in the provided files.
   - Chosen for its powerful data structures and data analysis tools.

3. scikit-learn: Used for machine learning algorithms and preprocessing tools.
   - Version: Not specified in the provided files.
   - Chosen for its comprehensive collection of machine learning tools and compatibility with TPOT.

4. dill: Used for object serialization and deserialization.
   - Version: Not specified in the provided files.
   - Chosen for its ability to serialize complex Python objects, including machine learning models.

## Configuration
The TPOT handler supports several configuration options that can be passed using the `USING` syntax when creating a model:

1. `generations` (default: 10): Number of iterations for the pipeline optimization process.
2. `population_size` (default: 100): Number of individuals to retain in the genetic programming population every generation.
3. `max_time_mins` (default: None): Maximum time in minutes for TPOT to optimize the pipeline.
4. `n_jobs` (default: -1): Number of parallel processes to use for evaluating pipelines.

Example usage:
```sql
CREATE MODEL mindsdb.my_tpot_model
FROM my_database
  (SELECT * FROM my_table)
PREDICT target_column
USING
  engine = 'TPOT',
  generations = 20,
  population_size = 200,
  max_time_mins = 60,
  n_jobs = 4;
```

These configuration options allow users to control the trade-off between optimization time and model performance, as well as resource utilization during the model creation process.

The TPOT handler automatically handles data type inference and categorical data encoding, simplifying the model creation process for users. However, it's important to note that TPOT may require significant computational resources and time for large datasets or complex problems, especially when using a large number of generations or a large population size.