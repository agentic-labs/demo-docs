---
title: "anyscale_endpoints_handler.py"
---

Here's a detailed documentation of the `AnyscaleEndpointsHandler` class:

## High-level description
The `AnyscaleEndpointsHandler` class is a specialized handler for connecting to and making inferences with the Anyscale Endpoints API. It inherits from the `OpenAIHandler` class and customizes certain behaviors and configurations specific to Anyscale Endpoints.

## Code Structure
The `AnyscaleEndpointsHandler` class extends the `OpenAIHandler` class, overriding and adding methods to handle Anyscale Endpoints-specific functionality. It uses configuration settings from `anyscale_handler_config` and interacts with the Anyscale API for various operations.

## References
This code references the following external components:
- `OpenAIHandler` from `mindsdb.integrations.handlers.openai_handler.openai_handler`
- `anyscale_handler_config` from `mindsdb.integrations.handlers.anyscale_endpoints_handler.settings`
- Various utility functions from `mindsdb.integrations.utilities.handler_utils` and `mindsdb.integrations.libs.llm.utils`

## Symbols

### AnyscaleEndpointsHandler
#### Description
This class handles connection and inference with the Anyscale Endpoints API, extending the functionality of the `OpenAIHandler`.

#### Inputs
- `*args`: Variable length argument list.
- `**kwargs`: Arbitrary keyword arguments.

#### Internal Logic
1. Initializes with Anyscale-specific configurations.
2. Overrides methods from `OpenAIHandler` to customize behavior for Anyscale Endpoints.
3. Implements Anyscale-specific methods for engine creation, model creation, prediction, and fine-tuning.

### create_engine
#### Description
Validates the Anyscale Endpoints credentials on engine creation.

#### Inputs
| Name | Type | Description |
|:-----|:-----|:------------|
| connection_args | Dict | Connection arguments for the engine |

#### Internal Logic
1. Extracts the API key and other connection parameters.
2. Creates an OpenAI client with the provided credentials.
3. Checks the client connection by attempting to retrieve a model.

### create_validation
#### Description
Validates the Anyscale Endpoints credentials on model creation.

#### Inputs
| Name | Type | Description |
|:-----|:-----|:------------|
| target | Text | Target column, not required for LLMs |
| args | Dict | Handler arguments |
| **kwargs | Dict | Additional keyword arguments |

#### Internal Logic
1. Validates the presence of required arguments.
2. Extracts API credentials and creates an OpenAI client.
3. Checks the client connection.

### create
#### Description
Creates a model by connecting to the Anyscale Endpoints API.

#### Inputs
| Name | Type | Description |
|:-----|:-----|:------------|
| target | Text | Target column name |
| args | Dict | Model arguments |
| **kwargs | Dict | Additional keyword arguments |

#### Internal Logic
1. Sets the base and fine-tuned models based on the provided arguments.
2. Calls the parent `create` method with the updated arguments.

### predict
#### Description
Makes predictions using a model connected to the Anyscale Endpoints API.

#### Inputs
| Name | Type | Description |
|:-----|:-----|:------------|
| df | pd.DataFrame | Input data for predictions |
| args | Dict | Prediction arguments |

#### Outputs
| Name | Type | Description |
|:-----|:-----|:------------|
| result | pd.DataFrame | Predicted data |

#### Internal Logic
1. Sets the base and fine-tuned models based on the provided arguments.
2. Calls the parent `predict` method with the updated arguments.

### finetune
#### Description
Fine-tunes a supported model using the Anyscale Endpoints API.

#### Inputs
| Name | Type | Description |
|:-----|:-----|:------------|
| df | pd.DataFrame | Input data for fine-tuning |
| args | Dict | Fine-tuning arguments |

#### Internal Logic
1. Sets the models based on the provided arguments.
2. Calls the parent `finetune` method.
3. Updates the list of chat completion models to include the newly fine-tuned model.

### describe
#### Description
Describes a model or its metadata.

#### Inputs
| Name | Type | Description |
|:-----|:-----|:------------|
| attribute | Text | Attribute to describe ('args' or 'metadata') |

#### Outputs
| Name | Type | Description |
|:-----|:-----|:------------|
| result | pd.DataFrame | Model or metadata description |

#### Internal Logic
1. Retrieves model arguments from storage.
2. Returns a DataFrame with the requested information based on the attribute.

## Dependencies
| Dependency | Purpose |
|:-----------|:--------|
| openai | Interacting with the OpenAI API |
| pandas | Data manipulation and analysis |
| mindsdb.integrations.utilities.handler_utils | Utility functions for handlers |
| mindsdb.integrations.libs.llm.utils | Utility functions for LLM operations |
| mindsdb.integrations.handlers.openai_handler.openai_handler | Base OpenAI handler |
| mindsdb.integrations.handlers.anyscale_endpoints_handler.settings | Anyscale-specific configurations |

## Configuration
The class uses configuration settings from `anyscale_handler_config`, including:
- `DEFAULT_MODEL`: Default model to use
- `ANYSCALE_API_BASE`: Base URL for the Anyscale API
- `DEFAULT_MODE`: Default operation mode
- `SUPPORTED_MODES`: List of supported operation modes
- `RATE_LIMIT`: API rate limit
- `MAX_BATCH_SIZE`: Maximum batch size for API requests
- `DEFAULT_MAX_TOKENS`: Default maximum number of tokens

## Error Handling
The class implements error handling for API connection issues and invalid configurations. It raises exceptions with descriptive error messages when encountering problems during engine creation, model creation, or API interactions.

## Logging
The class uses the `log` module from `mindsdb.utilities` for logging debug information and errors.

This documentation provides a comprehensive overview of the `AnyscaleEndpointsHandler` class, its methods, and its functionality within the context of interacting with the Anyscale Endpoints API.