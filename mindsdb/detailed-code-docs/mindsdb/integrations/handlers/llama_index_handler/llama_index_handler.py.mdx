---
title: "llama_index_handler.py"
---

## High-level description
This code implements a LlamaIndexHandler class, which is an integration with the LlamaIndex data framework for LLM applications. It provides functionality to create, update, and predict using LlamaIndex models, supporting different types of data sources and query modes.

## Code Structure
The LlamaIndexHandler class inherits from BaseMLEngine and implements methods for model creation, prediction, and updating. It uses various LlamaIndex components such as VectorStoreIndex, OpenAI, and OpenAIEmbedding to process and query data. The class interacts with external storage (model_storage and engine_storage) to persist and retrieve model data and settings.

## Symbols

### LlamaIndexHandler
#### Description
This class handles the integration with the LlamaIndex framework, providing methods for creating, updating, and querying LlamaIndex models.

#### Inputs
| Name | Type | Description |
|:-----|:-----|:------------|
| *args | Any | Variable length argument list |
| **kwargs | Any | Arbitrary keyword arguments |

#### Internal Logic
- Initializes with default settings for index class, reader, and sets the generative flag.
- Implements methods for model creation, validation, updating, and prediction.
- Handles different types of data sources (DataFrame, web pages) and query modes (conversational, standard).

### create_validation
#### Description
Static method to validate the creation arguments for a LlamaIndex model.

#### Inputs
| Name | Type | Description |
|:-----|:-----|:------------|
| target | str | The target column name |
| args | Optional[Dict] | Dictionary of arguments for model creation |
| **kwargs | Any | Additional keyword arguments |

#### Internal Logic
- Checks if the 'using' clause is present in the arguments.
- Validates the arguments using the LlamaIndexModel.

### create
#### Description
Creates a LlamaIndex model using the provided data and arguments.

#### Inputs
| Name | Type | Description |
|:-----|:-----|:------------|
| target | str | The target column name |
| df | Optional[pd.DataFrame] | Input data for model creation |
| args | Optional[Dict] | Dictionary of arguments for model creation |

#### Internal Logic
- Handles different reader types (DFReader, SimpleWebPageReader).
- Sets up the index using the appropriate reader and data.
- Persists the created index to storage.

### update
#### Description
Updates the existing model with new arguments.

#### Inputs
| Name | Type | Description |
|:-----|:-----|:------------|
| args | Dict | New arguments to update the model |

#### Internal Logic
- Retrieves current arguments from storage.
- Updates the arguments with new values.
- Validates the new set of arguments.
- Saves the updated arguments to storage.

### predict
#### Description
Performs predictions using the created LlamaIndex model.

#### Inputs
| Name | Type | Description |
|:-----|:-----|:------------|
| df | Optional[pd.DataFrame] | Input data for prediction |
| args | Optional[Dict] | Additional arguments for prediction |

#### Outputs
| Name | Type | Description |
|:-----|:-----|:------------|
| result_df | pd.DataFrame | DataFrame containing questions and predicted answers |

#### Internal Logic
- Handles different prediction modes (conversational, standard).
- Sets up the query engine with appropriate settings.
- Processes input questions and generates responses.
- Returns results as a DataFrame.

### _get_service_context
#### Description
Sets up the LlamaIndex service context with OpenAI API key and model settings.

#### Internal Logic
- Retrieves OpenAI API key from various sources.
- Configures OpenAI LLM and embedding model settings.

### _setup_index
#### Description
Creates a VectorStoreIndex from the provided documents.

#### Inputs
| Name | Type | Description |
|:-----|:-----|:------------|
| documents | List[Document] | List of documents to index |

#### Outputs
| Name | Type | Description |
|:-----|:-----|:------------|
| index | VectorStoreIndex | Created index from the documents |

#### Internal Logic
- Sets up the service context.
- Creates and returns a VectorStoreIndex from the input documents.

## Dependencies
| Dependency | Purpose |
|:-----------|:--------|
| pandas | Data manipulation and analysis |
| openai | OpenAI API integration |
| llama_index | Core functionality for indexing and querying |
| mindsdb.integrations.libs.base | Base classes for ML engines |
| mindsdb.utilities.config | Configuration management |
| mindsdb.utilities.security | URL validation and security checks |
| mindsdb.integrations.handlers.llama_index_handler.settings | LlamaIndex specific settings |
| mindsdb.integrations.libs.api_handler_exceptions | Custom exception classes |
| mindsdb.integrations.utilities.handler_utils | Utility functions for handlers |

## Error Handling
The code implements various error checks and raises exceptions for invalid inputs or missing parameters. It uses custom exceptions like MissingConnectionParams for specific error cases.

## TODOs
- Provide extra_info in explain_target column
- Add all usual params to Settings