---
title: "Overview"
---

## High-level description
This directory contains the MLflow handler for MindsDB, which integrates MLflow models into the MindsDB ecosystem. The handler allows users to create predictors using MLflow models, make predictions, and retrieve model information within MindsDB.

## What does it do?
The MLflow handler enables MindsDB to interact with MLflow-served models. It provides functionality to:

1. Create a predictor by connecting to an MLflow server and validating a specified model.
2. Make predictions using the MLflow model by sending requests to a prediction endpoint.
3. Retrieve and format information about the MLflow model.

This integration allows users to leverage MLflow's model management capabilities within MindsDB, enabling them to use MLflow-trained models for predictions and analysis alongside other data sources and AI models in MindsDB.

## Key Files

1. `mlflow_handler.py`: This is the core file containing the `MLflowHandler` class, which implements the main functionality for interacting with MLflow models.

2. `__init__.py`: This file sets up the MLflow integration handler for MindsDB, including the handler class, version information, and other metadata.

3. `__about__.py`: Contains metadata information for the MindsDB MLflow handler, such as the title, package name, version, description, author, and licensing information.

4. `example.md`: Provides example commands and usage instructions for using the MLflow handler within MindsDB.

## Dependencies
The MLflow handler relies on the following external libraries:

1. `mlflow` (version not specified): Used for interacting with MLflow's model registry and tracking functionality.
2. `requests`: Used for making HTTP requests to the MLflow prediction endpoint.
3. `pandas`: Used for data manipulation and storage of predictions and model information.

These dependencies were chosen to facilitate seamless integration with MLflow and to handle data processing efficiently within the MindsDB ecosystem.

## Configuration
The MLflow handler uses the following configuration parameters:

1. `model_name`: The name of the MLflow model to be used.
2. `mlflow_server_url`: The URL of the MLflow server (e.g., 'http://0.0.0.0:5001/').
3. `mlflow_server_path`: The path to the MLflow server's backend store (e.g., 'sqlite:////path/to/mlflow.db').
4. `predict_url`: The URL for the MLflow model's prediction endpoint (e.g., 'http://localhost:5000/invocations').

These parameters are specified when creating a model in MindsDB using the `CREATE MODEL` SQL command, as shown in the `example.md` file.

## Example Usage
Here's a simplified example of how to use the MLflow handler in MindsDB:

```sql
-- Create a model that registers an MLFlow served model as an AI Table
CREATE MODEL mindsdb.mlflow_model
PREDICT target
USING
engine='mlflow',
model_name='my_mlflow_model',
mlflow_server_url='http://0.0.0.0:5001/',
mlflow_server_path='sqlite:////path/to/mlflow.db',
predict_url='http://localhost:5000/invocations';

-- Make predictions using the created model
SELECT target
FROM mindsdb.mlflow_model
WHERE text='Some input text';
```

This example demonstrates how to create a model using the MLflow handler and then use it for predictions within MindsDB.

The MLflow handler provides a bridge between MLflow's model management capabilities and MindsDB's AI-enhanced database functionality, allowing users to seamlessly incorporate MLflow models into their MindsDB workflows.