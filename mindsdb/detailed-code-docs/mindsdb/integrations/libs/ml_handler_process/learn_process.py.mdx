---
title: "learn_process.py"
---

## High-level description
This code implements a learning process for machine learning models in MindsDB. It handles the creation and fine-tuning of models, manages data integration, and handles various aspects of model storage and error handling.

## Code Structure
The main function `learn_process` orchestrates the entire learning process. It interacts with various components such as `DatabaseController`, `ModelStorage`, `HandlerStorage`, and `SQLQuery` to fetch data, create or fine-tune models, and manage model storage. The code also utilizes profiling and error handling mechanisms.

## Symbols

### `learn_process`
#### Description
This function is the main entry point for the learning process. It handles data fetching, model creation/fine-tuning, and error handling.

#### Inputs
| Name | Type | Description |
|:-----|:-----|:------------|
| data_integration_ref | dict | Reference to the data integration |
| problem_definition | dict | Definition of the problem to be solved |
| fetch_data_query | str | SQL query to fetch training data |
| project_name | str | Name of the project |
| model_id | int | ID of the model |
| integration_id | int | ID of the integration |
| base_model_id | int | ID of the base model (for fine-tuning) |
| set_active | bool | Whether to set the model as active |
| module_path | str | Path to the ML handler module |

#### Internal Logic
1. Sets up profiling context
2. Fetches training data based on the integration type
3. Creates or fine-tunes the model using the appropriate ML handler
4. Updates the model status and handles any errors
5. Commits changes to the database

#### Error Handling
Errors are caught, logged, and stored in the predictor record. The predictor status is set to ERROR in case of exceptions.

### `handlers_cacher`
#### Description
A cache for ML handlers to improve performance by reusing handler instances.

#### Internal Logic
Stores handlers with a timestamp and removes the least recently used handler when the cache size exceeds the maximum limit.

## Dependencies
| Dependency | Purpose |
|:-----------|:--------|
| importlib | For dynamically importing ML handler modules |
| mindsdb_sql | For SQL parsing and query execution |
| mindsdb.api.executor | For SQL query execution |
| mindsdb.utilities | For profiling, logging, and configuration |
| mindsdb.interfaces.storage | For database and file storage operations |
| mindsdb.integrations.utilities | For error formatting and SQL utilities |

## Error Handling
The code uses a try-except block to catch any exceptions during the learning process. Errors are logged, formatted, and stored in the predictor record. The predictor status is set to ERROR in case of exceptions.

## Logging
The code uses a logger (from `mindsdb.utilities.log`) to log error messages and tracebacks.

## Performance Considerations
1. The code uses profiling to measure performance at various stages of the learning process.
2. A handler cache (`handlers_cacher`) is used to improve performance by reusing handler instances.
3. Database operations are performed within a single session to reduce overhead.

This code is a crucial part of MindsDB's model training pipeline, handling various aspects of data integration, model creation, and error management. It's designed to be flexible, supporting different types of data integrations and ML handlers.