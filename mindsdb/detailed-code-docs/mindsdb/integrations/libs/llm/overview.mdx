---
title: "Overview"
---

## High-level description
This directory contains utility functions and configuration classes for working with Large Language Models (LLMs) in MindsDB. It provides a set of tools for preparing prompts, validating data formats for fine-tuning, and configuring different LLM providers such as OpenAI, Anthropic, Anyscale, LiteLLM, Ollama, and NVIDIA NIM.

## What does it do?
The code in this directory facilitates the integration of various LLM providers into MindsDB. It offers functionality to:

1. Generate formatted prompts from templates and data.
2. Configure LLM providers with specific parameters.
3. Validate and format data for fine-tuning LLMs.
4. Process and chunk code for LLM training.
5. Format context-question-answer data for fine-tuning.

These utilities enable developers to work with LLMs more efficiently within the MindsDB ecosystem, handling common tasks such as prompt generation, data preparation, and provider-specific configuration.

## Key Files

### config.py
This file defines configuration classes for various LLM providers using Pydantic. It includes:

- `BaseLLMConfig`: A base configuration class for all LLM providers.
- Provider-specific classes (e.g., `OpenAIConfig`, `AnthropicConfig`, `AnyscaleConfig`) that inherit from `BaseLLMConfig`.

Each configuration class contains fields relevant to its specific LLM service, such as API keys, model names, and generation parameters.

### utils.py
This file contains utility functions for working with LLMs:

- `get_completed_prompts`: Generates formatted prompts from templates and data.
- `get_llm_config`: Returns the configuration for a given LLM provider.
- `ft_jsonl_validation`: Validates JSON lines for LLM fine-tuning.
- `ft_chat_format_validation`: Implements a finite state machine to validate chat formats.
- `ft_formatter`: Entry point for data preparation in LLM fine-tuning.
- `ft_chat_formatter`: Formats chat data for fine-tuning.
- `ft_code_formatter`: Processes and chunks code for LLM training.
- `ft_cqa_formatter`: Formats context-question-answer data for fine-tuning.

These functions handle various aspects of working with LLMs, from data preparation to configuration management.

## Dependencies
The main dependencies used in this directory are:

1. Pydantic: For data validation and settings management in configuration classes.
2. Pandas: For data manipulation in utility functions.
3. NumPy: For numerical operations in utility functions.
4. LangChain: Used for text splitting utilities in code formatting.

These dependencies are crucial for the functionality provided by the utility functions and configuration classes.

## Configuration
The configuration classes defined in `config.py` allow for flexible setup of different LLM providers. Each provider-specific class (e.g., `OpenAIConfig`, `AnthropicConfig`) contains fields relevant to that provider, such as:

- Model name
- API keys
- Temperature
- Max tokens
- Request timeouts
- Custom API base URLs

These configuration classes ensure that the necessary parameters for each LLM provider are properly defined and validated.

In summary, this directory provides a comprehensive set of tools for working with LLMs in MindsDB, offering flexibility in provider configuration and utility functions for common LLM-related tasks. The code is designed to be modular and extensible, allowing for easy integration of new LLM providers and additional utility functions as needed.