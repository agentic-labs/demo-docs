---
title: "rag.py"
---

## High-level description
This code defines a `LangChainRAGPipeline` class that builds a Retrieval-Augmented Generation (RAG) pipeline using LangChain's LCEL (LangChain Expression Language) components. It provides methods to create RAG pipelines with different types of retrievers, including a simple vector store retriever, an auto retriever, and a multi-vector retriever.

## Code Structure
The `LangChainRAGPipeline` class contains methods to build and configure the RAG pipeline. It uses various components from the LangChain library and custom retrievers defined in the MindsDB project. The class provides flexibility in creating different types of RAG pipelines based on the configuration provided.

## Symbols

### `LangChainRAGPipeline`
#### Description
This class builds a RAG pipeline using LangChain LCEL components. It provides methods to create pipelines with different types of retrievers and returned sources.

#### Inputs
| Name | Type | Description |
|:-----|:-----|:------------|
| retriever_runnable | Runnable | The retriever component of the RAG pipeline |
| prompt_template | str | The template for the RAG prompt |
| llm | BaseLLM | The language model to be used in the pipeline |

#### Methods

### `with_returned_sources()`
#### Description
Builds a RAG pipeline that returns both the answer and the sources used to generate it.

#### Outputs
| Name | Type | Description |
|:-----|:-----|:------------|
| rag_chain_with_source | RunnableSerializable | A runnable RAG pipeline that returns the answer and sources |

#### Internal Logic
1. Defines a `format_docs` function to handle different types of document inputs.
2. Creates a `ChatPromptTemplate` from the provided template.
3. Constructs the RAG chain using LCEL components, including document formatting, prompt template application, LLM invocation, and output parsing.
4. Combines the retriever and question input in parallel, then assigns the answer using the RAG chain.

### `from_retriever(cls, config: RAGPipelineModel)`
#### Description
Class method that builds a RAG pipeline using a simple vector store retriever.

#### Inputs
| Name | Type | Description |
|:-----|:-----|:------------|
| config | RAGPipelineModel | Configuration model for the RAG pipeline |

#### Internal Logic
1. Creates a `VectorStoreOperator` using the provided configuration.
2. Returns a new `LangChainRAGPipeline` instance using the vector store retriever.

### `from_auto_retriever(cls, config: RAGPipelineModel)`
#### Description
Class method that builds a RAG pipeline using an AutoRetriever.

#### Inputs
| Name | Type | Description |
|:-----|:-----|:------------|
| config | RAGPipelineModel | Configuration model for the RAG pipeline |

#### Internal Logic
1. Sets a default retriever prompt template if not provided.
2. Creates an `AutoRetriever` instance and gets its runnable form.
3. Returns a new `LangChainRAGPipeline` instance using the auto retriever.

### `from_multi_vector_retriever(cls, config: RAGPipelineModel)`
#### Description
Class method that builds a RAG pipeline using a MultiVectorRetriever.

#### Inputs
| Name | Type | Description |
|:-----|:-----|:------------|
| config | RAGPipelineModel | Configuration model for the RAG pipeline |

#### Internal Logic
1. Creates a `MultiVectorRetriever` instance and gets its runnable form.
2. Returns a new `LangChainRAGPipeline` instance using the multi-vector retriever.

## Dependencies
| Dependency | Purpose |
|:-----------|:--------|
| langchain_core | Provides core components for building the RAG pipeline |
| mindsdb.integrations.utilities.rag | Custom retrievers and utilities for RAG pipelines |

## Error Handling
The code includes basic error handling, raising `ValueError` exceptions when required components (prompt or LLM) are None in the `with_returned_sources` method.

## Performance Considerations
The RAG pipeline is built using LangChain's LCEL components, which are designed for efficient composition and execution of language model workflows. The use of different retriever types (simple vector store, auto, and multi-vector) allows for flexibility in optimizing retrieval performance based on the specific use case and data characteristics.

This code provides a flexible and extensible framework for building RAG pipelines with different retriever types, allowing for easy integration with various data sources and retrieval strategies in the MindsDB ecosystem.