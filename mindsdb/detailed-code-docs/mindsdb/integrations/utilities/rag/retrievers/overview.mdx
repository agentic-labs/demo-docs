---
title: "Overview"
---

## High-level description

This directory contains implementations of various retriever classes for a Retrieval-Augmented Generation (RAG) pipeline. The retrievers are designed to efficiently search and retrieve relevant documents or information from a corpus, which can then be used in downstream natural language processing tasks. The directory includes a base abstract class, an auto-retriever, and a multi-vector retriever, each serving different retrieval strategies and use cases.

## What does it do?

The code in this directory provides different ways to retrieve information from a collection of documents:

1. It defines a base structure for all retrievers, ensuring consistency across implementations.
2. It implements an auto-retriever that can automatically extract metadata from documents and use it for more intelligent querying.
3. It provides a multi-vector retriever that can store multiple representations of each document, allowing for more nuanced and flexible retrieval.

These retrievers can be used in a RAG pipeline to find relevant information from a large corpus of documents based on a given query. This retrieved information can then be used to augment the input to language models, improving their ability to generate accurate and contextually relevant responses.

## Key Files

1. `base.py`: Defines the `BaseRetriever` abstract base class, which serves as a template for all retriever implementations.

2. `auto_retriever.py`: Implements the `AutoRetriever` class, which uses LangChain to create a self-query retriever. It automatically extracts metadata from documents, creates a vector store, and uses a language model to generate queries for retrieving relevant information.

3. `multi_vector_retriever.py`: Implements the `MultiVectorRetriever` class, which stores multiple vectors per document for more nuanced retrieval. It supports different modes of operation, including splitting documents, summarizing them, or both.

## Dependencies

The code in this directory relies on several external libraries and frameworks:

1. LangChain: Used extensively for creating retrievers, vector stores, and integrating with language models. It provides the core functionality for many of the retrieval operations.

2. Pandas: Used in the `AutoRetriever` for data manipulation and analysis, particularly in metadata extraction.

3. OpenAI's ChatGPT: The `MultiVectorRetriever` uses `ChatOpenAI` for generating document summaries.

4. UUID: Used in the `MultiVectorRetriever` for generating unique identifiers for documents.

These dependencies were likely chosen for their robust implementations of vector operations, language model integrations, and data processing capabilities, which are crucial for efficient and effective document retrieval.

## Configuration

The retrievers in this directory use configuration objects, typically of type `RAGPipelineModel`, to set various parameters and options. These configuration objects likely include settings such as:

- The type of embedding model to use
- Vector store settings
- Language model configurations
- Retrieval mode settings (for the `MultiVectorRetriever`)
- Cardinality thresholds (for the `AutoRetriever`)

The exact configuration fields would depend on the specific implementation of the `RAGPipelineModel` class, which is not provided in the given code snippets.

In addition, the `MultiVectorRetriever` uses an enum `MultiVectorRetrieverMode` to specify its operation mode (SPLIT, SUMMARIZE, or BOTH), which affects how documents are processed and stored.

## Code Examples

Here's an example of how the `AutoRetriever` might be used:

```python
from mindsdb.integrations.utilities.rag.settings import RAGPipelineModel
from mindsdb.integrations.utilities.rag.retrievers.auto_retriever import AutoRetriever

# Assume we have a configuration object
config = RAGPipelineModel(...)

# Create the auto retriever
retriever = AutoRetriever(config)

# Get the runnable retriever
runnable_retriever = retriever.as_runnable()

# Use the retriever to get relevant documents
relevant_docs = runnable_retriever.invoke("What is the capital of France?")
```

And here's how you might use the `MultiVectorRetriever`:

```python
from mindsdb.integrations.utilities.rag.settings import RAGPipelineModel
from mindsdb.integrations.utilities.rag.retrievers.multi_vector_retriever import MultiVectorRetriever, MultiVectorRetrieverMode

# Assume we have a configuration object
config = RAGPipelineModel(...)

# Create the multi-vector retriever in BOTH mode
retriever = MultiVectorRetriever(config)
retriever.mode = MultiVectorRetrieverMode.BOTH

# Get the runnable retriever
runnable_retriever = retriever.as_runnable()

# Use the retriever to get relevant documents
relevant_docs = runnable_retriever.invoke("Tell me about machine learning")
```

These retrievers form a crucial part of a RAG pipeline, enabling efficient and context-aware information retrieval to enhance the capabilities of language models in various applications.