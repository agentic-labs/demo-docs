---
title: "mindsdb_tables.py"
---

## High-level description
This file defines various table classes that represent system tables in MindsDB. These tables provide information about models, databases, ML engines, handlers, jobs, triggers, chatbots, knowledge bases, skills, agents, and views within the MindsDB system. The classes implement methods to fetch and structure data for these tables.

## Code Structure
The file defines multiple table classes, each inheriting from the `MdbTable` or `Table` base class. These classes represent different system tables in MindsDB. Each class typically has a `name` attribute, a `columns` list, and a `get_data` class method that retrieves and structures the data for the table.

## Symbols

### `MdbTable` class
#### Description
A base class for MindsDB tables, inheriting from `Table`. It sets the `visible` attribute to `True`.

### `ModelsTable` class
#### Description
Represents the "MODELS" table, providing information about ML models in MindsDB.

#### Internal Logic
The `get_data` method fetches model information from projects and structures it into a pandas DataFrame.

### `DatabasesTable` class
#### Description
Represents the "DATABASES" table, providing information about databases in MindsDB.

#### Internal Logic
The `get_data` method retrieves database information and structures it into a pandas DataFrame.

### `MLEnginesTable` class
#### Description
Represents the "ML_ENGINES" table, providing information about ML engines in MindsDB.

#### Internal Logic
The `get_data` method fetches ML integration information and structures it into a pandas DataFrame.

### `HandlersTable` class
#### Description
Represents the "HANDLERS" table, providing information about handlers in MindsDB.

#### Internal Logic
The `get_data` method retrieves handler information and structures it into a pandas DataFrame.

### `JobsTable` class
#### Description
Represents the "JOBS" table, providing information about jobs in MindsDB.

#### Internal Logic
The `get_data` method fetches job information and structures it into a pandas DataFrame.

### `TriggersTable` class
#### Description
Represents the "TRIGGERS" table, providing information about triggers in MindsDB.

#### Internal Logic
The `get_data` method retrieves trigger information and structures it into a pandas DataFrame.

### `ChatbotsTable` class
#### Description
Represents the "CHATBOTS" table, providing information about chatbots in MindsDB.

#### Internal Logic
The `get_data` method fetches chatbot information and structures it into a pandas DataFrame.

### `KBTable` class
#### Description
Represents the "KNOWLEDGE_BASES" table, providing information about knowledge bases in MindsDB.

#### Internal Logic
The `get_data` method retrieves knowledge base information and structures it into a pandas DataFrame.

### `SkillsTable` class
#### Description
Represents the "SKILLS" table, providing information about skills in MindsDB.

#### Internal Logic
The `get_data` method fetches skill information and structures it into a pandas DataFrame.

### `AgentsTable` class
#### Description
Represents the "AGENTS" table, providing information about agents in MindsDB.

#### Internal Logic
The `get_data` method retrieves agent information and structures it into a pandas DataFrame.

### `ViewsTable` class
#### Description
Represents the "VIEWS" table, providing information about views in MindsDB.

#### Internal Logic
The `get_data` method fetches view information and structures it into a pandas DataFrame.

## Dependencies
- pandas
- mindsdb_sql
- mindsdb.interfaces.agents.agents_controller
- mindsdb.interfaces.jobs.jobs_controller
- mindsdb.interfaces.skills.skills_controller
- mindsdb.interfaces.database.views
- mindsdb.interfaces.database.projects
- mindsdb.api.executor.datahub.datanodes.system_tables

## Error Handling
The code includes basic error handling, such as checking for the existence of projects and handling potential exceptions when fetching data.

## Performance Considerations
The code fetches data from various controllers and structures it into pandas DataFrames. For large datasets, this approach might have performance implications and could be optimized if needed.