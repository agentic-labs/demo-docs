---
title: "Overview"
---

## High-level description
This directory contains the implementation of various SQL query execution steps for MindsDB. It includes classes for handling different types of SQL operations such as applying predictors, inserting data, joining tables, map-reduce operations, preparing columns, subselects, unions, and updates. These step calls are part of the SQL query execution pipeline in MindsDB.

## What does it do?
The code in this directory implements the execution logic for different SQL operations within MindsDB. It processes SQL queries by breaking them down into specific steps and executing each step accordingly. This includes:

1. Applying machine learning predictors to data
2. Inserting and updating data in tables
3. Joining datasets
4. Performing map-reduce operations for parallel processing
5. Preparing and retrieving column information
6. Executing subqueries and unions
7. Handling data projections and limitations

These steps work together to enable complex SQL query execution on both traditional data and machine learning predictions within the MindsDB ecosystem.

## Entry points
The main entry point for this directory is the `__init__.py` file, which imports and exposes the various step call classes. Each specific operation is implemented in its own file, such as `apply_predictor_step.py`, `insert_step.py`, `join_step.py`, etc.

The execution flow typically starts from the SQL query executor, which uses these step calls to process different parts of a SQL query. The executor would instantiate the appropriate step call class based on the query plan and invoke its `call` method to execute that specific step of the query.

## Key Files
1. `apply_predictor_step.py`: Implements steps for applying machine learning predictors to data.
2. `insert_step.py`: Handles data insertion and table creation operations.
3. `join_step.py`: Implements join operations between datasets.
4. `map_reduce_step.py`: Handles partitioned data processing and variable-based query execution.
5. `prepare_steps.py`: Retrieves column information for predictors and tables.
6. `subselect_step.py`: Executes subselect and general query operations on dataframes.
7. `union_step.py`: Performs union operations between result sets.
8. `update_step.py`: Executes SQL UPDATE statements.

Each of these files contains one or more classes that inherit from `BaseStepCall` and implement specific SQL operations.

## Dependencies
The code in this directory relies on several key dependencies:

1. `mindsdb_sql`: Provides SQL parsing and planning utilities.
2. `pandas`: Used for dataframe operations and data manipulation.
3. `numpy`: Used for numerical operations and handling NaN values.
4. `mindsdb.api.executor.sql_query.result_set`: Provides the ResultSet class for handling query results.
5. `mindsdb.api.executor.exceptions`: Contains custom exception classes for error handling.
6. `mindsdb.utilities.config`: Provides configuration settings for MindsDB.
7. `mindsdb.utilities.context_executor`: Offers multi-threading functionality for parallel processing.

These dependencies are crucial for the functioning of the SQL query execution steps, enabling efficient data processing, SQL parsing, and integration with the broader MindsDB ecosystem.

## Configuration
The code uses MindsDB's configuration system to determine certain behaviors, such as:

1. The maximum number of query partitions in cloud environments (in `map_reduce_step.py`).
2. Whether the execution is happening in a cloud or local environment, which affects threading decisions.

These configuration options allow the SQL execution steps to adapt to different deployment scenarios and optimize performance accordingly.

In summary, this directory forms a crucial part of MindsDB's SQL query execution system, providing implementations for various SQL operations and integrating with MindsDB's predictor and data handling capabilities. It enables complex SQL queries that can seamlessly incorporate machine learning predictions alongside traditional data operations.