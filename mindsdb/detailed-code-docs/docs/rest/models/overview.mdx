---
title: "Overview"
---

## High-level description

The `docs/rest/models` directory contains documentation for REST API endpoints related to managing machine learning models in MindsDB. These endpoints provide functionality for creating, training, deploying, querying, and managing models within projects.

## What does it do?

This directory provides documentation for various operations on machine learning models in MindsDB:

1. Creating, training, and deploying models
2. Listing existing models
3. Retrieving information about specific models
4. Making predictions using trained models (both single and batch predictions)
5. Describing model details, including accuracies and feature importances
6. Removing models
7. Managing model versions (in progress)
8. Fine-tuning models (in progress)
9. Retraining models (in progress)

These endpoints allow users to interact with MindsDB's machine learning capabilities through a REST API, enabling them to integrate model management and prediction functionalities into their applications or workflows.

## Key Files

1. `train-model.mdx`: Documents the endpoint for creating, training, and deploying a model.
2. `list-models.mdx`: Describes how to retrieve a list of all models in a project.
3. `list-model.mdx`: Explains how to get information about a specific model.
4. `query-model.mdx`: Details the process of getting a single prediction from a model.
5. `query-model-joined-with-data.mdx`: Outlines how to get batch predictions from a model.
6. `describe-model.mdx`: Shows how to retrieve detailed information about a model, including accuracies and feature importances.
7. `delete-model.mdx`: Explains the process of removing a model from a project.

## Configuration

The documentation mentions that the REST API endpoints can be used with MindsDB running locally at `http://127.0.0.1:47334/api`. This information is consistently provided across the files, indicating that users should configure their API requests to target this local endpoint.

## Dependencies

While the documentation doesn't explicitly mention dependencies, it's clear that these endpoints are part of the MindsDB REST API. Users would need to have MindsDB installed and running locally to use these endpoints.

## Code Snippets and Examples

The documentation includes several code snippets and examples to illustrate how to use the API endpoints. Here are a few notable examples:

1. Creating and training a model:

```json
curl --request POST \
  --url http://127.0.0.1:47334/api/projects/mindsdb/models \
  --header 'Content-Type: application/json' \
  --data '{
    "name": "home_rentals_model",
    "engine": "mindsdb",
    "project": "mindsdb",
    "data_source": "home_rentals",
    "predict": "rental_price",
    "options": {
      "time_aim": 10
    }
  }'
```

2. Getting a single prediction:

```json
curl --request POST \
  --url http://127.0.0.1:47334/api/projects/mindsdb/models/home_rentals_model/predict \
  --header 'Content-Type: application/json' \
  --data '{
    "data": [
      {
        "sqft": "823",
        "location": "good",
        "neighborhood": "downtown",
        "days_on_market": "10"
      }
    ]
  }'
```

3. Describing a model:

```json
[
    {
        "accuracies": {
            "r2_score": 0.999
        },
        "column_importances": {
            "days_on_market": 0.116,
            "location": 0.054,
            "neighborhood": 0.0,
            "number_of_bathrooms": 0.009,
            "number_of_rooms": 0.297,
            "sqft": 1.037
        },
        "inputs": [
            "number_of_rooms",
            "number_of_bathrooms",
            "sqft",
            "location",
            "days_on_market",
            "neighborhood"
        ],
        "model": "encoders --&gt; dtype_dict --&gt; dependency_dict --&gt; model --&gt; problem_definition --&gt; identifiers --&gt; imputers --&gt; accuracy_functions",
        "outputs": [
            "rental_price"
        ]
    }
]
```

These examples demonstrate how to interact with the API for various model-related operations, providing users with practical guidance on using the endpoints in their applications.