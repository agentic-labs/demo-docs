---
title: "schema.py"
---

## High-level description
This code defines the schema and data structures for a monitoring system, likely for a data pipeline or analytics platform. It includes models for representing test results, model runs, artifacts (models, sources, exposures), and various metadata associated with these entities. The code also provides APIs for fetching and processing this data.

## Code Structure
The code is organized into several modules, each focusing on a specific aspect of the monitoring system:
1. `schema.py`: Defines the core data models using Pydantic.
2. `models.py`: Provides APIs for fetching and processing model-related data.
3. `filters.py`: Handles filtering of test results and model runs.
4. `groups.py`: Manages grouping of artifacts based on various criteria.
5. `report.py`: Aggregates data from various sources to generate a comprehensive report.

These modules interact with each other to provide a cohesive monitoring and reporting system.

## Symbols

### NormalizedArtifactSchema
#### Description
A base schema for normalized artifacts, including common fields like owners, tags, and paths.

#### Inputs
| Name | Type | Description |
|:-----|:-----|:------------|
| owners | Optional[List[str]] | List of owners for the artifact |
| tags | Optional[List[str]] | List of tags associated with the artifact |
| model_name | str | Name of the model (artifact) |
| normalized_full_path | str | Normalized full path of the artifact |
| fqn | Optional[str] | Fully qualified name of the artifact |

#### Internal Logic
- Includes validators for tags, owners, and normalized_full_path to ensure proper formatting and handling of input data.

### ModelRunSchema
#### Description
Represents a single run of a model, including execution details and status.

#### Inputs
| Name | Type | Description |
|:-----|:-----|:------------|
| id | str | Unique identifier for the run |
| time_utc | str | UTC timestamp of the run |
| status | str | Status of the run |
| full_refresh | Optional[bool] | Whether it was a full refresh |
| materialization | Optional[str] | Materialization type |
| execution_time | float | Execution time of the run |

#### Internal Logic
- Includes a validator for time_utc to ensure proper ISO format.

### ModelRunsSchema
#### Description
Represents multiple runs of a model, including aggregated statistics and individual run details.

#### Inputs
| Name | Type | Description |
|:-----|:-----|:------------|
| unique_id | str | Unique identifier for the model |
| schema_name | Optional[str] | Schema name |
| name | str | Model name |
| status | str | Overall status |
| last_exec_time | float | Last execution time |
| median_exec_time | float | Median execution time |
| compiled_code | Optional[str] | Compiled code of the model |
| last_generated_at | str | Timestamp of last generation |
| exec_time_change_rate | float | Execution time change rate |
| totals | TotalsModelRunsSchema | Aggregated totals |
| runs | List[ModelRunSchema] | List of individual runs |

### ModelsAPI
#### Description
API for fetching and processing model-related data.

#### Methods
- `get_models_runs`: Fetches and processes model run data.
- `get_models`: Retrieves model metadata.
- `get_sources`: Retrieves source metadata.
- `get_exposures`: Retrieves exposure metadata.
- `get_test_coverages`: Retrieves test coverage information for models.

### ReportAPI
#### Description
API for generating comprehensive reports by aggregating data from various sources.

#### Methods
- `get_report_data`: Main method to generate the report data, combining information from tests, models, sources, and other components.

## Dependencies
- pydantic: Used for data validation and settings management.
- elementary.utils: Various utility functions and classes.
- elementary.clients.api.api_client: Base API client.
- elementary.monitor.fetchers: Data fetchers for various components.

## Configuration
The code uses various configuration options, mainly through method parameters in the API classes. These include options for filtering data, specifying time ranges, and controlling the level of detail in the reports.

## Error Handling
Error handling is primarily done through exceptions. The `get_report_data` method in `ReportAPI` catches and returns any exceptions that occur during the report generation process.

## Logging
The code uses a custom logger (`get_logger`) for logging, but the specific logging implementation is not shown in the provided snippets.

This code forms the core of a monitoring and reporting system for a data pipeline or analytics platform, providing structured data models and APIs to fetch, process, and aggregate various types of monitoring data.