---
title: "Overview"
---

## High-level description
This directory contains dbt (data build tool) models, configurations, and exposures for a data transformation project. It includes SQL and Python models for various data transformations, schema definitions, and exposure configurations for downstream analytics tools.

## What does it do?
The code in this directory implements several data transformation and modeling processes:

1. Customer and Order Data Transformation: SQL models (`customers.sql` and `orders.sql`) select and transform data from staging tables, preparing it for analysis.

2. Metrics Processing: Multiple models in the `metrics` subdirectory handle different aspects of metrics data, including incremental updates, table creation, and view generation.

3. Test and Utility Models: The `one.sql` and `fail_model.sql` files provide utility models for testing and demonstration purposes.

4. Data Quality and Documentation: The `schema.yml` file defines the structure of the models and sets up data quality tests.

5. Exposures: The `exposures.yml` file defines how the transformed data is used in downstream dashboards, providing lineage and documentation for data consumers.

These processes create a structured data pipeline that transforms raw data into analysis-ready formats, ensures data quality, and documents data usage for business intelligence purposes.

## Key Files

1. `customers.sql` and `orders.sql`: These files define the core data models for customer and order information.

2. `metrics` subdirectory: Contains models for processing metrics data using various materialization strategies (incremental, table, view) and includes a Python-based model for additional flexibility.

3. `schema.yml`: Defines the structure of the `customers`, `orders`, and `one` models, including column descriptions and data quality tests.

4. `exposures.yml`: Configures two dashboard exposures (customers and orders) that use the transformed data.

5. `test_data.yaml`: Defines the structure of test data sources used in the project.

6. `one.sql` and `fail_model.sql`: Utility models for testing and demonstration purposes.

## Dependencies
The main dependency for this project is dbt (data build tool), which is used for defining, organizing, and executing the data transformation models. The project likely relies on a specific version of dbt, though the exact version is not specified in the provided files.

## Configuration
The project uses various configuration options:

1. Materialization strategies: Models use different materialization strategies (table, incremental, view) depending on their purpose and performance requirements.

2. Tags and Metadata: Models can be tagged and have metadata (such as owner) assigned using dbt variables.

3. Schema Configuration: The `test_data.yaml` file allows for dynamic schema naming using a combination of the target schema and an optional suffix.

4. Exposures: The `exposures.yml` file configures how transformed data is used in downstream dashboards, including ownership and maturity information.

5. Data Quality Tests: The `schema.yml` file sets up data quality tests, including uniqueness checks and exposure schema validity tests.

This configuration allows for flexible and robust data transformation processes, with clear documentation and lineage tracking for data consumers.