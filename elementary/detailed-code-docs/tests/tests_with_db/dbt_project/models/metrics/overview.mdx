---
title: "Overview"
---

## High-level description
This directory contains dbt (data build tool) models for metrics, implemented using both SQL and Python. The models demonstrate various materialization strategies and data transformation techniques, showcasing different ways to aggregate and process metrics data within a dbt project.

## What does it do?
The code in this directory defines how to calculate, transform, and store metrics data. It uses a combination of SQL and Python to create different representations of metrics, which can be materialized as tables or views in a data warehouse. These models serve as the foundation for data analysis and reporting, providing structured and optimized access to metrics data.

The workflows implemented include:
1. Direct data copying from source tables
2. Incremental data updates for efficiency
3. Data consolidation from multiple sources
4. Custom Python-based data processing

These processes allow for flexible and efficient handling of metrics data, catering to various analytical needs and performance requirements.

## Key Files

### SQL Models

#### `metrics_incremental.sql`
This file defines an incremental dbt model that efficiently updates metrics data. It selects all data from the `metrics_seed2` source table and materializes it incrementally, meaning only new or updated data is added when the model is run. This approach is particularly useful for large, frequently updated datasets, as it minimizes processing time and resource usage.

#### `metrics_table.sql`
This model creates a table named `metrics_table` by selecting all data from the `metrics_seed1` source table. It materializes the data as a complete table, providing a direct copy of the source data in the data warehouse. This approach is suitable for smaller datasets or when a full snapshot of the data is required.

#### `metrics_view.sql`
This model creates a view named `metrics_view` that combines data from two source tables, `metrics_seed1` and `metrics_seed2`, using a UNION ALL operation. This consolidated view provides a comprehensive representation of the metrics data from both sources, allowing for unified analysis across multiple data inputs.

### Python Model

The Python model, defined in a separate file (likely named something like `python_model.py`), showcases how to create a dbt model using Python instead of SQL. This model:

1. Is configured to materialize as a table using `dbt.config(materialized="table")`.
2. Sources data from the "test_data" source, specifically the "metrics_seed3" table.
3. Returns the sourced data without any transformations, demonstrating how Python can be used to interact with dbt and database sessions.

This Python-based approach allows for more complex data transformations and the use of Python libraries if needed, providing greater flexibility in data processing within the dbt framework.

## Dependencies
The models in this directory rely on the following main dependency:

- dbt (data build tool): This is the core framework used for defining, organizing, and executing the data transformation models. It provides the infrastructure for materializing the models as tables or views in the data warehouse.

## Configuration
The models use various configuration options to control their behavior:

1. Materialization strategies:
   - Table: Used in `metrics_table.sql` and the Python model to create full table copies.
   - Incremental: Used in `metrics_incremental.sql` for efficient updates.
   - View: Used in `metrics_view.sql` to create a virtual table combining multiple sources.

2. Source references:
   The models reference source tables using dbt's `{{ source() }}` function, which allows for centralized management of data sources. The following sources are used:
   - `test_data.metrics_seed1`
   - `test_data.metrics_seed2`
   - `test_data.metrics_seed3`

These configurations allow for flexible and optimized data processing, catering to different use cases and performance requirements within the metrics data pipeline.