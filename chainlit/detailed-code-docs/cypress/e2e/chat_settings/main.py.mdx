---
title: "main.py"
---

## High-level description
This code defines a Chainlit chat application with customizable settings for OpenAI and Stability AI models. It sets up various input widgets for users to adjust model parameters and handles the initialization and updating of these settings.

## Code Structure
The code consists of two main functions decorated with Chainlit decorators: `start()` for initializing chat settings, and `setup_agent()` for handling settings updates. These functions use the `ChatSettings` class and various input widget types imported from the Chainlit library.

## References
This code references the Chainlit library, specifically the `chainlit` module and the `input_widget` submodule.

## Symbols

### `start()`
#### Description
This asynchronous function is triggered at the start of a chat session. It initializes and sends the chat settings to the user interface.

#### Inputs
None

#### Outputs
None

#### Internal Logic
1. Creates a `ChatSettings` object with a list of input widgets.
2. Sends the settings to the user interface using the `send()` method.

The function defines several input widgets:
- A `Select` widget for choosing the OpenAI model
- A `Switch` widget for enabling/disabling token streaming
- A `Slider` widget for adjusting the OpenAI temperature
- Multiple `Slider` widgets for Stability AI parameters (steps, cfg_scale, image width, and height)

### `setup_agent(settings)`
#### Description
This asynchronous function is called when the chat settings are updated. It sends a confirmation message to the user.

#### Inputs
| Name | Type | Description |
|:-----|:-----|:------------|
| settings | dict | The updated settings |

#### Outputs
None

#### Internal Logic
Sends a message to the user confirming that the settings have been updated.

## Dependencies
| Dependency | Purpose |
|:-----------|:--------|
| chainlit | Main library for building the chat application |
| chainlit.input_widget | Provides input widget classes for creating interactive settings |

## Configuration
The code defines several configuration options for OpenAI and Stability AI models:

| Option | Type | Default | Description |
|:-------|:-----|:--------|:------------|
| Model | Select | gpt-3.5-turbo | OpenAI model selection |
| Streaming | Switch | True | Enable/disable token streaming for OpenAI |
| Temperature | Slider | 1 | OpenAI temperature setting (0-2) |
| SAI_Steps | Slider | 30 | Stability AI inference steps (0-150) |
| SAI_Cfg_Scale | Slider | 7 | Stability AI cfg scale (1-35) |
| SAI_Width | Slider | 512 | Stability AI image width in pixels (0-2048) |
| SAI_Height | Slider | 512 | Stability AI image height in pixels (0-2048) |

## Error Handling
This code does not implement explicit error handling. It relies on the underlying Chainlit library to handle any errors that may occur during the execution of the decorated functions.

## API/Interface Reference
This code doesn't explicitly define an API, but it uses Chainlit's decorators to define event handlers:

| Decorator | Function | Description |
|:----------|:---------|:------------|
| @cl.on_chat_start | start() | Triggered when a new chat session starts |
| @cl.on_settings_update | setup_agent(settings) | Triggered when chat settings are updated |

These decorators integrate the defined functions into Chainlit's event system, allowing them to respond to specific events in the chat application lifecycle.