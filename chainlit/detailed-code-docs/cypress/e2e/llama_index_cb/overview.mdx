---
title: "Overview"
---

## High-level description
This directory contains the implementation and testing of a Llama Index Callback functionality within a Chainlit application. It includes configuration files, a main Python script demonstrating the usage of LlamaIndexCallbackHandler, and a Cypress test file for end-to-end testing of the UI interactions.

## What does it do?
The code in this directory simulates a retrieval and Language Model (LLM) event sequence in a chat interface. It demonstrates how to use callbacks to track and display these events, providing a visual representation of the retrieval and LLM processes to the user. The Cypress test ensures that the UI correctly displays the messages, prompts, and elements generated by these simulated events.

## Key Files

1. `.chainlit` (Configuration file):
   - Configures the Chainlit application settings, including project features, UI customization, and theming options.
   - Sets up security measures, such as disabling HTML processing in messages and configuring file upload limitations.

2. `main.py` (Main application script):
   - Implements the core functionality of the Llama Index Callback demonstration.
   - Uses the `LlamaIndexCallbackHandler` to simulate retrieval and LLM events.
   - Sends messages and updates to the Chainlit chat interface.

3. `spec.cy.ts` (Cypress test file):
   - Contains end-to-end tests for the Llama Index Callback functionality.
   - Verifies that messages with prompts and elements are correctly sent and displayed in the UI.

## Dependencies
The project relies on several key dependencies:

1. Chainlit: Used for creating the chat interface and handling callbacks.
2. LlamaIndex: Provides the core functionality for retrieval and LLM operations, although in this case, it's simulated.
3. Cypress: Used for end-to-end testing of the UI.

## Configuration
The `.chainlit` file contains extensive configuration options for the Chainlit application. Key configurations include:

- Telemetry settings
- Session timeout
- CORS settings
- Feature toggles (e.g., HTML processing, LaTeX support)
- UI customization options
- Theming preferences

For example:

```toml
[project]
enable_telemetry = true
session_timeout = 3600
cache = false
allow_origins = ["*"]

[features]
unsafe_allow_html = false
latex = false
auto_tag_thread = true
```

The configuration file allows for fine-tuning of the application's behavior and appearance without modifying the core code.

## Code Examples

1. Simulating a retrieval event in `main.py`:

```python
await cl.make_async(handler.on_event_start)(
    event_type=CBEventType.RETRIEVE,
    payload={"query": "test query"},
)
await asyncio.sleep(0.2)
await cl.make_async(handler.on_event_end)(
    event_type=CBEventType.RETRIEVE,
    payload={
        "query": "test query",
        "nodes": [
            NodeWithScore(
                node=TextNode(text="test text", id_="test_id"),
                score=0.5,
            )
        ],
    },
)
```

2. Testing UI interactions in `spec.cy.ts`:

```typescript
it('should be able to send messages to the UI with prompts and elements', () =&gt; {
  cy.get('.step').should('have.length', 3);
  cy.contains('.step', 'retrieve').click();
  cy.get('.tool-call').first().find('.message-content').should('contain', 'Source 0');
});
```

These examples showcase how the application simulates events and how the tests verify the correct display of information in the UI.

In summary, this directory implements a demonstration of Llama Index Callback functionality within a Chainlit application, providing both the core implementation and end-to-end tests to ensure proper functionality and user experience.