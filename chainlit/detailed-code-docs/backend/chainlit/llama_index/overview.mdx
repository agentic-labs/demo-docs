---
title: "Overview"
---

## High-level description
This directory contains code for integrating LlamaIndex functionality with the Chainlit framework. It includes a module initializer and a callback handler for LlamaIndex operations. The main purpose is to provide version checking for the LlamaIndex library and to manage events and steps during LlamaIndex operations within the Chainlit UI.

## What does it do?
The code in this directory performs two main functions:

1. Version Checking: It ensures that the installed version of the `llama_index.core` library meets the minimum required version (0.10.15). This check is performed when the module is imported, helping to prevent compatibility issues.

2. Event Handling and UI Integration: The `LlamaIndexCallbackHandler` class tracks and manages events during LlamaIndex operations. It creates and updates steps in the Chainlit UI, providing real-time feedback on the progress of operations such as retrieval, querying, and language model interactions. This allows users to visualize the workflow of LlamaIndex operations within the Chainlit interface.

## Key Files

1. `__init__.py`: This file performs the version check for the `llama_index.core` library. It raises a `ValueError` if the installed version is below the required minimum.

2. `callbacks.py`: This file contains the `LlamaIndexCallbackHandler` class, which is responsible for handling LlamaIndex events and updating the Chainlit UI accordingly. It extends the `TokenCountingHandler` from LlamaIndex and overrides methods to create and manage steps in the UI.

## Dependencies
The main dependencies for this directory are:

1. `llama_index.core` (version &gt;= 0.10.15): This is the core LlamaIndex library that provides the functionality being integrated with Chainlit.

2. `chainlit`: This framework is used for creating the user interface and managing the context of the application.

3. `literalai`: Used for handling chat and completion generations.

These dependencies were chosen to combine the powerful indexing and querying capabilities of LlamaIndex with the interactive UI features of Chainlit, creating a more user-friendly and visually informative experience for working with large language models and document retrieval.

## Configuration
There are no explicit configuration files in this directory. However, the `LlamaIndexCallbackHandler` class accepts configuration parameters:

- `event_starts_to_ignore`: A list of event types to ignore when an event starts.
- `event_ends_to_ignore`: A list of event types to ignore when an event ends.

These parameters allow for customization of which LlamaIndex events should be tracked and displayed in the Chainlit UI.

The code also uses the Chainlit context and emitter, which may require configuration in the broader Chainlit application setup.

Here's an example of how the `LlamaIndexCallbackHandler` might be instantiated with custom ignore lists:

```python
from llama_index.core.callbacks import CBEventType
from backend.chainlit.llama_index.callbacks import LlamaIndexCallbackHandler

custom_ignore_start = [CBEventType.CHUNKING, CBEventType.EMBEDDING]
custom_ignore_end = [CBEventType.TREE, CBEventType.NODE_PARSING]

handler = LlamaIndexCallbackHandler(
    event_starts_to_ignore=custom_ignore_start,
    event_ends_to_ignore=custom_ignore_end
)
```

This configuration would create a handler that ignores chunking and embedding events at the start, and tree and node parsing events at the end, while still tracking other events in the Chainlit UI.