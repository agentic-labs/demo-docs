---
title: "callbacks.py"
---

Here's a comprehensive documentation for the `backend/chainlit/langchain/callbacks.py` file:

## High-level description
This file implements a custom callback handler for Langchain, providing functionality to trace and stream the execution of Langchain components. It integrates with Chainlit's UI and data persistence layer, allowing for real-time updates and logging of the language model's execution steps.

## Code Structure
The main class `LangchainTracer` inherits from `BaseTracer`, `GenerationHelper`, and `FinalStreamHelper`. It implements various callback methods to handle different stages of Langchain's execution, such as starting an LLM call, processing new tokens, and handling errors.

## Symbols

### `FinalStreamHelper`
#### Description
A helper class to manage streaming the final answer from a chain.

#### Internal Logic
- Tracks the last tokens to determine if the answer has been reached.
- Provides methods to check if the answer is reached and to append new tokens.

### `GenerationHelper`
#### Description
A helper class to manage chat and completion generations.

#### Internal Logic
- Stores and processes chat and completion generations.
- Provides methods to convert message formats and build LLM settings.

### `LangchainTracer`
#### Description
The main callback handler for Langchain, integrating with Chainlit's UI and data layer.

#### Inputs
| Name | Type | Description |
|:-----|:-----|:------------|
| answer_prefix_tokens | Optional[List[str]] | Tokens that prefix the answer |
| stream_final_answer | bool | Whether to stream the final answer |
| force_stream_final_answer | bool | Whether to force stream the first response |
| to_ignore | Optional[List[str]] | Runs to ignore for enhanced readability |
| to_keep | Optional[List[str]] | Runs to keep within ignored runs |

#### Internal Logic
- Implements various callback methods for different Langchain events (e.g., `on_chat_model_start`, `on_llm_start`, `on_llm_new_token`).
- Manages the creation, updating, and removal of steps in the UI.
- Handles streaming of tokens and final answers.
- Integrates with Chainlit's data persistence layer.

### `LangchainCallbackHandler`
An alias for `LangchainTracer`.

### `AsyncLangchainCallbackHandler`
An alias for `LangchainTracer`.

## Side Effects
- Interacts with Chainlit's context, emitter, and data layer to update the UI and persist data.
- Modifies the global state by updating steps and streaming content.

## Dependencies
| Dependency | Purpose |
|:-----------|:--------|
| chainlit.context | Accessing the current Chainlit context |
| chainlit.message | Working with Chainlit message objects |
| chainlit.step | Working with Chainlit step objects |
| langchain.callbacks.tracers.base | Base class for the tracer |
| langchain.callbacks.tracers.schemas | Schemas for Langchain runs |
| langchain.schema | Langchain schema objects |
| literalai | Types and helpers for literal AI operations |

## Error Handling
The code includes error handling for data persistence operations, logging errors if they occur during step updates or creations.

## Logging
The code uses Chainlit's logger to log errors, particularly when failing to persist data.

This callback handler is crucial for integrating Langchain with Chainlit, providing real-time updates and logging of the language model's execution process. It allows for a detailed trace of the execution steps, which can be displayed in the Chainlit UI and persisted for later analysis.