---
title: "docker-compose-cpu-embeddings.yml"
---

## High-level description
This Docker Compose file defines a multi-container application for running various text embedding and reranking models using CPU-based images. It sets up five services, each running a different model for text processing tasks such as document embedding, query embedding, and reranking.

## Code Structure
The file defines five services: `splade-doc`, `splade-query`, `jina`, `bgem3`, and `reranker`. Each service is configured to use a specific model and is exposed on a different port.

## Symbols

### `splade-doc`
#### Description
This service runs the SPLADE (Sparse Lexical and Expansion) model for document embedding.

#### Internal Logic
- Uses the `naver/efficient-splade-VI-BT-large-doc` model
- Exposes port 4000
- Mounts a local `./data` directory to `/data` in the container

### `splade-query`
#### Description
This service runs the SPLADE model for query embedding.

#### Internal Logic
- Uses the `naver/efficient-splade-VI-BT-large-query` model
- Exposes port 5000
- Mounts a local `./data` directory to `/data` in the container

### `jina`
#### Description
This service runs the Jina AI embeddings model.

#### Internal Logic
- Uses the `jinaai/jina-embeddings-v2-base-en` model
- Exposes port 6000
- Mounts a local `./data` directory to `/data` in the container

### `bgem3`
#### Description
This service runs the BGE-M3 embeddings model.

#### Internal Logic
- Uses the `BAAI/bge-m3` model
- Exposes port 7000
- Mounts a local `./data` directory to `/data` in the container

### `reranker`
#### Description
This service runs a reranker model for improving search results.

#### Internal Logic
- Uses the `BAAI/bge-reranker-base` model
- Exposes port 8000
- Mounts a local `./data` directory to `/data` in the container

## Dependencies
| Dependency | Purpose |
|:-----------|:--------|
| ghcr.io/huggingface/text-embeddings-inference:cpu-1.4 | Base image for SPLADE models |
| ghcr.io/huggingface/text-embeddings-inference:cpu-1.5 | Base image for Jina, BGE-M3, and reranker models |

## Configuration
| Option | Type | Default | Description |
|:-------|:-----|:--------|:------------|
| --model-id | string | varies | Specifies the model to be used for each service |
| --revision | string | main | Specifies the model revision to use |
| --pooling | string | splade | Specifies the pooling method (only for SPLADE models) |

## API/Interface Reference
| Endpoint | Method | Request | Response | Description |
|:---------|:-------|:--------|:---------|:------------|
| http://localhost:4000 | POST | Text data | Embeddings | SPLADE document embeddings |
| http://localhost:5000 | POST | Text data | Embeddings | SPLADE query embeddings |
| http://localhost:6000 | POST | Text data | Embeddings | Jina embeddings |
| http://localhost:7000 | POST | Text data | Embeddings | BGE-M3 embeddings |
| http://localhost:8000 | POST | Text data | Reranked results | BGE reranker |

Note: The exact API endpoints and request/response formats would depend on the specific implementation of the text-embeddings-inference image and the models used. This table provides a general idea of how these services might be accessed.