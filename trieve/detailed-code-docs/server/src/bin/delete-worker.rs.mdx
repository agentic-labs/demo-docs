---
title: "delete-worker.rs"
---

Here's a detailed documentation for the `delete-worker.rs` file:

## High-level description
This file implements a worker service that handles the asynchronous deletion of datasets and their associated data. It processes deletion requests from a Redis queue, performs the deletion operations, and handles error cases.

## Code Structure
The main function sets up the environment, initializes connections to various services (PostgreSQL, Redis, Clickhouse), and starts the delete worker service. The `delete_worker` function is the core of the service, continuously processing deletion requests from the Redis queue.

## Symbols

### `main`
#### Description
The entry point of the program. It sets up the environment, initializes connections, and starts the delete worker service.

#### Internal Logic
1. Initializes Sentry for error tracking if configured.
2. Sets up database and Redis connections.
3. Initializes Clickhouse client and event queue if analytics are enabled.
4. Starts the delete worker service.

### `delete_worker`
#### Description
The main worker function that continuously processes dataset deletion requests from a Redis queue.

#### Inputs
| Name | Type | Description |
|:-----|:-----|:------------|
| should_terminate | Arc&lt;AtomicBool&gt; | Flag to signal termination of the worker |
| redis_pool | web::Data&lt;RedisPool&gt; | Redis connection pool |
| web_pool | web::Data&lt;Pool&gt; | Database connection pool |
| clickhouse_client | web::Data&lt;clickhouse::Client&gt; | Clickhouse client for analytics |
| event_queue | web::Data&lt;EventQueue&gt; | Queue for processing events |

#### Internal Logic
1. Establishes a connection to Redis.
2. Continuously polls the Redis queue for deletion requests.
3. Processes each request by:
   - Fetching the dataset information
   - Clearing or deleting the dataset based on the request type
   - Handling any errors and potentially re-queueing failed requests
4. Deletes the organization if it was the last dataset for that organization.

### `readd_error_to_queue`
#### Description
Handles errors during the deletion process by re-adding the failed request to the queue or moving it to a dead letter queue after multiple attempts.

#### Inputs
| Name | Type | Description |
|:-----|:-----|:------------|
| payload | DeleteMessage | The original deletion request |
| error | ServiceError | The error that occurred |
| event_queue | web::Data&lt;EventQueue&gt; | Queue for processing events |
| redis_pool | web::Data&lt;RedisPool&gt; | Redis connection pool |

#### Outputs
| Name | Type | Description |
|:-----|:-----|:------------|
| Result | Result&lt;(), ServiceError&gt; | Success or failure of the re-queue operation |

## Dependencies
- diesel_async: For asynchronous database operations
- redis: For Redis operations
- sentry: For error tracking and monitoring
- signal_hook: For handling termination signals
- tracing_subscriber: For logging and tracing
- trieve_server: Custom server module containing various data models and operators

## Error Handling
The code implements extensive error handling, logging errors, and using Sentry to capture and report errors. Failed deletion attempts are re-queued with an increasing attempt count, and after three failures, they are moved to a dead letter queue.

## Logging
The code uses the `log` crate for logging information and errors throughout the execution of the worker.

## TODOs
There are no explicit TODOs in the code.

This delete worker is a critical component for managing the lifecycle of datasets in the Trieve system, ensuring that deletions are processed reliably and asynchronously.