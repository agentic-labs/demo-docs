---
title: "model_operator.rs"
---

Here's a high-level description and documentation of the `model_operator.rs` file:

## High-level description
This file contains functions for generating and managing various types of embeddings (dense vectors, sparse vectors, and BM25 embeddings) for text chunks. It interfaces with external embedding services and Qdrant for vector operations. The code handles different embedding strategies, including semantic, full-text, and BM25 embeddings, and provides functionality for cross-encoding and reranking.

## Code Structure
The file defines several structs and functions that work together to create and manage embeddings:
- `EmbeddingParameters`: Defines parameters for embedding requests.
- Functions like `get_dense_vector`, `get_sparse_vector`, `get_dense_vectors`, `get_sparse_vectors`, `get_bm25_embeddings`: Generate different types of embeddings.
- `cross_encoder`: Performs cross-encoding for reranking.

These functions often interact with external services (like OpenAI) and internal components (like Qdrant) to perform their operations.

## Symbols

### `get_dense_vector`
#### Description
Generates a dense vector embedding for a given message using an external embedding service.

#### Inputs
- `message`: String to embed
- `distance_phrase`: Optional `SemanticBoost` for adjusting the embedding
- `embed_type`: String indicating the type of embedding ("doc" or "query")
- `dataset_config`: `DatasetConfiguration` for the dataset

#### Outputs
- Result containing a vector of f32 values (the embedding) or a ServiceError

#### Internal Logic
1. Sets up Sentry transaction for monitoring.
2. Determines the embedding API key and base URL.
3. Prepares the input for the embedding service.
4. Sends a request to the embedding service.
5. Processes the response and applies any semantic boost.

### `get_sparse_vector`
#### Description
Generates a sparse vector embedding for a given message using an external embedding service.

#### Inputs
- `message`: String to embed
- `embed_type`: String indicating the type of embedding ("doc" or "query")

#### Outputs
- Result containing a vector of (u32, f32) tuples (the sparse embedding) or a ServiceError

#### Internal Logic
1. Determines the server origin based on the embed_type.
2. Prepares the input for the embedding service.
3. Sends a request to the embedding service.
4. Processes the response to create the sparse vector.

### `get_dense_vectors`
#### Description
Generates dense vector embeddings for multiple content items in batch.

#### Inputs
- `content_and_distances`: Vector of (String, Option&lt;SemanticBoost&gt;) tuples
- `embed_type`: String indicating the type of embedding
- `dataset_config`: `DatasetConfiguration` for the dataset
- `reqwest_client`: HTTP client for making requests

#### Outputs
- Result containing a vector of vectors of f32 values (the embeddings) or a ServiceError

#### Internal Logic
1. Sets up Sentry transaction for monitoring.
2. Determines the embedding API key and base URL.
3. Splits the input into batches of 30.
4. Processes each batch in parallel, sending requests to the embedding service.
5. Applies any semantic boosts to the resulting embeddings.

### `get_sparse_vectors`
#### Description
Generates sparse vector embeddings for multiple content items in batch.

#### Inputs
- `content_and_boosts`: Vector of (String, Option&lt;FullTextBoost&gt;) tuples
- `embed_type`: String indicating the type of embedding
- `reqwest_client`: HTTP client for making requests

#### Outputs
- Result containing a vector of vectors of (u32, f32) tuples (the sparse embeddings) or a ServiceError

#### Internal Logic
1. Determines the server origin based on the embed_type.
2. Splits the input into batches of 30.
3. Processes each batch in parallel, sending requests to the embedding service.
4. Applies any full-text boosts to the resulting embeddings.

### `get_bm25_embeddings`
#### Description
Generates BM25 embeddings for a batch of chunks.

#### Inputs
- `chunks_and_boost`: Vector of (String, Option&lt;FullTextBoost&gt;) tuples
- `avg_len`, `b`, `k`: BM25 parameters

#### Outputs
- Vector of vectors of (u32, f32) tuples (the BM25 embeddings)

#### Internal Logic
1. Tokenizes the input chunks.
2. Calculates term frequencies.
3. Applies the BM25 formula to generate the embeddings.

### `cross_encoder`
#### Description
Performs cross-encoding for reranking search results.

#### Inputs
- `query`: The search query
- `page_size`: Number of results per page
- `results`: Vector of `ScoreChunkDTO` to rerank
- `dataset_config`: `DatasetConfiguration` for the dataset

#### Outputs
- Result containing a vector of reranked `ScoreChunkDTO` or an actix_web::Error

#### Internal Logic
1. Sets up Sentry transaction for monitoring.
2. Prepares the input for the cross-encoder service.
3. Sends requests to the cross-encoder service in batches.
4. Processes the responses to rerank the input results.

## Dependencies
The code relies on several external crates and internal modules, including:
- `qdrant_client` for vector operations
- `openai_dive` for interfacing with OpenAI's API
- `reqwest` for HTTP requests
- `sentry` for error tracking and performance monitoring
- Internal modules for data models and error handling

## Error Handling
The code uses the `ServiceError` enum for error handling, which is propagated through the `Result` type. Errors are logged and, in some cases, sent to Sentry for monitoring.

## Performance Considerations
- The code uses batching for processing multiple embeddings in parallel.
- It implements caching mechanisms (e.g., Redis) to store and retrieve embeddings.
- The cross-encoder function processes results in batches to handle large result sets efficiently.

This code is critical for the search and recommendation functionality of the application, as it handles the creation and management of various types of embeddings used for semantic search and content analysis.