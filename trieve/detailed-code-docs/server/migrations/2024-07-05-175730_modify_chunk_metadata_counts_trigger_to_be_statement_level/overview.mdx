---
title: "Overview"
---

## High-level description
This directory contains SQL migration scripts for modifying the trigger mechanism that updates chunk metadata counts in a database. The migration aims to improve performance by changing from a row-level trigger to a statement-level trigger approach for maintaining chunk counts in the `dataset_usage_counts` table based on changes in the `chunk_metadata` table.

## What does it do?
The migration scripts in this directory modify how the database keeps track of chunk counts for datasets. Instead of updating the count for each individual row insertion or deletion, the new approach calculates the total change in chunk count for each database operation and updates the count in a single step. This change is designed to improve performance, especially when dealing with large numbers of insertions or deletions.

Here's a simplified explanation of the process:
1. When chunks of data are added to or removed from a dataset, the database needs to keep track of how many chunks each dataset has.
2. Previously, it would count each chunk one by one as they were added or removed.
3. With this change, it now waits until all the chunks for an operation are processed, then updates the total count in one go.
4. This is more efficient, especially when dealing with lots of chunks at once.

## Key Files

### up.sql
This file contains the SQL commands to implement the new statement-level trigger approach. It does the following:
1. Drops the existing row-level trigger and associated function.
2. Creates a new function `update_chunk_metadata_counts` that calculates the total change in chunk count for a given operation.
3. Creates two new statement-level triggers: one for insertions and one for deletions in the `chunk_metadata` table.

Key aspects of the new function:
- It determines the affected dataset and calculates the total count change.
- For insertions, it either creates a new entry in `dataset_usage_counts` or updates an existing one.
- For deletions, it decreases the chunk count in `dataset_usage_counts`.

### down.sql
This file contains the SQL commands to revert the changes made by `up.sql`, essentially rolling back to the previous row-level trigger approach. It:
1. Drops the new statement-level triggers and function.
2. Recreates the original function and row-level trigger.

The recreated function in `down.sql`:
- Handles both insertions and deletions.
- Updates the `chunk_count` in `dataset_usage_counts` for each affected row individually.

## Configuration
This migration does not rely on any external configuration files or environment variables. The changes are applied directly to the database schema and trigger mechanisms.

## Performance Considerations
The primary goal of this migration is to improve performance. By switching from row-level triggers to statement-level triggers, the database can handle bulk operations more efficiently. Instead of updating the `dataset_usage_counts` table for each individual row change, it now calculates the total change and applies it in a single update. This can significantly reduce the number of database operations, especially for large batch inserts or deletes in the `chunk_metadata` table.

Here's a code snippet from `up.sql` that illustrates the performance improvement:

```sql
CREATE OR REPLACE FUNCTION update_chunk_metadata_counts()
RETURNS TRIGGER AS $$
DECLARE
    affected_dataset_id UUID;
    new_count INT;
BEGIN
    -- Get the dataset_id from the modified rows
    SELECT dataset_id INTO affected_dataset_id FROM modified LIMIT 1;

    -- Calculate the count of affected rows
    SELECT COUNT(*) INTO new_count FROM modified;

    -- Update the dataset_usage_counts table
    IF (TG_OP = 'INSERT') THEN
        INSERT INTO dataset_usage_counts (dataset_id, chunk_count)
        VALUES (affected_dataset_id, new_count)
        ON CONFLICT (dataset_id) DO UPDATE
        SET chunk_count = dataset_usage_counts.chunk_count + new_count;
    ELSIF (TG_OP = 'DELETE') THEN
        UPDATE dataset_usage_counts
        SET chunk_count = GREATEST(0, chunk_count - new_count)
        WHERE dataset_id = affected_dataset_id;
    END IF;

    RETURN NULL;
END;
$$ LANGUAGE plpgsql;
```

This function calculates the total count change for all affected rows in a single operation, rather than processing each row individually. This approach is more efficient, especially for large-scale data operations.