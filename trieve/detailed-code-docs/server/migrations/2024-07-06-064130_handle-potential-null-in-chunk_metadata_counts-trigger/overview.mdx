---
title: "Overview"
---

## High-level description
This directory contains SQL migration scripts for handling potential null values in chunk metadata counts. It consists of two files: `up.sql` and `down.sql`. These scripts modify triggers and functions related to updating chunk counts in the `dataset_usage_counts` table when changes occur in the `chunk_metadata` table.

## What does it do?
The migration scripts in this directory implement a mechanism to maintain accurate chunk counts for datasets. When chunks of data are added to or removed from a dataset, these scripts ensure that the count of chunks for each dataset is updated correctly in a separate table called `dataset_usage_counts`. 

The `up.sql` script introduces a new implementation that handles potential null values in the chunk metadata, while the `down.sql` script reverts these changes to the previous implementation. This allows for more robust handling of edge cases where null values might occur in the dataset information.

## Key Files

### up.sql
This file contains the SQL commands to implement the new logic for handling potential null values in chunk metadata counts. It does the following:

1. Drops existing triggers and functions related to chunk metadata counts.
2. Creates a new `update_chunk_metadata_counts` function that:
   - Retrieves the `dataset_id` from the modified data.
   - Checks for null `dataset_id` and exits if found.
   - Calculates the new chunk count.
   - Updates the `dataset_usage_counts` table based on whether it's an INSERT or DELETE operation.
3. Creates two new triggers:
   - `increase_chunk_metadata_counts_trigger` for INSERT operations.
   - `delete_chunk_metadata_counts_trigger` for DELETE operations.

Both triggers call the `update_chunk_metadata_counts` function after their respective operations on the `chunk_metadata` table.

### down.sql
This file contains the SQL commands to revert the changes made by `up.sql`. It:

1. Drops the triggers and function created by `up.sql`.
2. Recreates the `update_chunk_metadata_counts` function with the previous logic.
3. Recreates the `increase_chunk_metadata_counts_trigger` and `delete_chunk_metadata_counts_trigger` triggers using the recreated function.

The main difference in the reverted function is that it doesn't include the null check for `dataset_id` and directly proceeds with updating the `dataset_usage_counts` table.

## Configuration
This migration doesn't rely on any external configuration files or environment variables. The changes are applied directly to the database schema and triggers.

Here's an example of how the `update_chunk_metadata_counts` function in `up.sql` handles potential null values:

```sql
CREATE OR REPLACE FUNCTION update_chunk_metadata_counts() RETURNS TRIGGER AS $$
DECLARE
    dataset_id UUID;
    new_count INTEGER;
BEGIN
    SELECT modified.dataset_id INTO dataset_id FROM modified LIMIT 1;
    
    IF dataset_id IS NULL THEN
        RETURN NULL;
    END IF;

    SELECT COUNT(*) INTO new_count FROM modified;

    IF TG_OP = 'INSERT' THEN
        INSERT INTO dataset_usage_counts (dataset_id, chunk_count)
        VALUES (dataset_id, new_count)
        ON CONFLICT (dataset_id) DO UPDATE
        SET chunk_count = dataset_usage_counts.chunk_count + new_count;
    ELSIF TG_OP = 'DELETE' THEN
        UPDATE dataset_usage_counts
        SET chunk_count = dataset_usage_counts.chunk_count - new_count
        WHERE dataset_usage_counts.dataset_id = dataset_id;
    END IF;

    RETURN NULL;
END;
$$ LANGUAGE plpgsql;
```

This function now checks if the `dataset_id` is null and exits early if it is, preventing potential errors or incorrect updates to the `dataset_usage_counts` table.

The migration scripts in this directory ensure that the database maintains accurate chunk counts for datasets, even when dealing with potential null values in the chunk metadata. This improves the robustness and reliability of the data management system.