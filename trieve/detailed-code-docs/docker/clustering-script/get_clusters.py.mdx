---
title: "get_clusters.py"
---

## High-level description
This script performs clustering on search queries from multiple datasets stored in a ClickHouse database. It uses the HDBSCAN algorithm for clustering, generates topic names for each cluster using Claude AI, and stores the results back in the database.

## Code Structure
The script defines several functions that work together to fetch data, perform clustering, generate topics, and insert results back into the database. The main execution flow is in the `if __name__ == "__main__":` block, which iterates through datasets and applies the clustering process.

## Symbols

### `fetch_dataset_vectors`
#### Description
Fetches search query data from the ClickHouse database for a given dataset.

#### Inputs
| Name | Type | Description |
|:-----|:-----|:------------|
| client | clickhouse_connect.driver.client.Client | ClickHouse client connection |
| dataset_id | uuid.UUID | ID of the dataset to fetch |
| limit | int | Maximum number of rows to fetch (default: 5000) |

#### Outputs
| Name | Type | Description |
|:-----|:-----|:------------|
| rows | list | List of tuples containing query data |

#### Internal Logic
1. Constructs a SQL query to select recent, non-duplicate search queries for the given dataset.
2. Executes the query and returns the result rows.

### `get_clusters`
#### Description
Organizes clustering results into a dictionary of clusters.

#### Inputs
| Name | Type | Description |
|:-----|:-----|:------------|
| hdbscan | HDBSCAN | Fitted HDBSCAN clustering object |
| data | list | Original data used for clustering |

#### Outputs
| Name | Type | Description |
|:-----|:-----|:------------|
| clusters | dict | Dictionary of clusters with labels as keys and lists of (data, probability, index) tuples as values |

### `get_datasets`
#### Description
Retrieves all unique dataset IDs from the search_queries table.

#### Inputs
| Name | Type | Description |
|:-----|:-----|:------------|
| client | clickhouse_connect.driver.client.Client | ClickHouse client connection |

#### Outputs
| Name | Type | Description |
|:-----|:-----|:------------|
| rows | list | List of tuples containing dataset IDs |

### `hdbscan_clustering`
#### Description
Performs HDBSCAN clustering on the input data.

#### Inputs
| Name | Type | Description |
|:-----|:-----|:------------|
| data | list | List of data points to cluster |

#### Outputs
| Name | Type | Description |
|:-----|:-----|:------------|
| hdb | HDBSCAN | Fitted HDBSCAN clustering object |

#### Internal Logic
1. Extracts vectors from the input data.
2. Creates an HDBSCAN object with min_cluster_size=30.
3. Fits the HDBSCAN object to the vectors and returns it.

### `get_topics`
#### Description
Generates topic names for each cluster using Claude AI.

#### Inputs
| Name | Type | Description |
|:-----|:-----|:------------|
| hdbscan | HDBSCAN | Fitted HDBSCAN clustering object |
| clusters | dict | Dictionary of clusters |
| data | list | Original data used for clustering |
| top_n | int | Number of top queries to use for topic generation (default: 5) |

#### Outputs
| Name | Type | Description |
|:-----|:-----|:------------|
| topics | dict | Dictionary of cluster labels and their corresponding topic names |

#### Internal Logic
1. For each cluster, selects the top N queries with the highest probabilities.
2. Sends these queries to Claude AI to generate a 3-5 word topic name.
3. Stores the generated topic names in a dictionary.

### `insert_centroids`
#### Description
Inserts clustering results (topics and memberships) into the database.

#### Inputs
| Name | Type | Description |
|:-----|:-----|:------------|
| client | clickhouse_connect.driver.client.Client | ClickHouse client connection |
| data | list | Original data used for clustering |
| dataset_id | tuple | Dataset ID |
| topics | dict | Dictionary of cluster labels and their corresponding topic names |
| clusters | dict | Dictionary of clusters |

#### Internal Logic
1. Generates UUIDs for each topic.
2. Inserts topic information into the `cluster_topics` table.
3. Creates membership rows for each query in each cluster.
4. Inserts membership information into the `search_cluster_memberships` table.

## Dependencies
| Dependency | Purpose |
|:-----------|:--------|
| datetime | Handling date and time operations |
| os | Accessing environment variables |
| uuid | Generating unique identifiers |
| anthropic | Interacting with Claude AI for topic generation |
| clickhouse_connect | Connecting to and querying ClickHouse database |
| numpy | Numerical operations and array handling |
| sklearn.cluster | HDBSCAN clustering algorithm |
| scipy.spatial.distance | Cosine distance calculation (unused in the current code) |
| dotenv | Loading environment variables from a .env file |

## Error Handling
The main script wraps the clustering process for each dataset in a try-except block, catching and printing any exceptions that occur during processing. This allows the script to continue processing other datasets if an error occurs with one.

## Logging
The script uses print statements to log progress and errors, such as when a dataset is skipped due to insufficient data or when clustering is completed for a dataset.

## TODOs
- The `cosine` import from `scipy.spatial.distance` is unused and could be removed.
- Consider adding more robust error handling and logging mechanisms.
- The `anthropic_client` is created globally but used only in the `get_topics` function. Consider moving its initialization closer to its usage.
- The `limit` parameter in `fetch_dataset_vectors` is set to 5000 by default but used as 3000 in the main script. Consider aligning these values or making it a configurable parameter.