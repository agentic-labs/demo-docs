---
title: "Overview"
---

## High-level description
This directory contains the implementation of a Kafka sink for Flipt's audit logging system. It provides functionality to encode audit events into Protobuf or Avro formats and publish them to a Kafka topic. The implementation supports various configurations, including TLS, SASL authentication, and schema registry integration.

## What does it do?
The Kafka sink in this directory allows Flipt to send audit events to a Kafka topic for further processing or analysis. Here's a simplified explanation of the workflow:

1. When an action occurs in Flipt that needs to be audited, an audit event is created.
2. The Kafka sink receives these audit events.
3. Depending on the configuration, the sink encodes the events into either Protobuf or Avro format.
4. If schema registry is enabled, the sink registers the schema and uses it for encoding.
5. The encoded events are then published to a specified Kafka topic.
6. External systems can consume these events from the Kafka topic for monitoring, analysis, or other purposes.

This process allows Flipt to maintain a detailed, scalable audit log of important actions and changes within the system.

## Key Files

### kafka.go
This file contains the main implementation of the Kafka sink. It defines the `Sink` struct and provides methods for creating a new sink, sending audit events, and managing the Kafka client connection. Key features include:

- Configuration of the Kafka client with support for TLS and SASL authentication.
- Integration with schema registry for Avro and Protobuf encodings.
- Asynchronous publishing of audit events to the Kafka topic.
- Error handling and logging throughout the process.

### avro.go
This file implements the Avro encoder for audit events. It provides functionality to:

- Parse and store the Avro schema for audit events.
- Encode `audit.Event` structs into Avro-formatted byte arrays.
- Handle conversion of event payloads to a format compatible with Avro encoding.

### protobuf.go
This file implements the Protobuf encoder for audit events. It offers:

- A method to return the Protobuf schema for audit events.
- Functionality to encode `audit.Event` structs into Protobuf messages.
- Conversion of timestamps and payloads to Protobuf-compatible formats.

### encoding_test.go and kafka_test.go
These files contain unit tests for the Kafka sink implementation, covering various scenarios such as:

- Encoding of different event types and payloads.
- Successful audit event sending with different encodings and configurations.
- Error cases like unsupported encodings, authentication failures, and TLS issues.

## Dependencies
The Kafka sink implementation relies on several external libraries:

1. `github.com/twmb/franz-go`: A Kafka client library used for interacting with Kafka brokers.
2. `github.com/hamba/avro`: Used for Avro encoding of audit events.
3. `google.golang.org/protobuf`: Used for Protobuf encoding of audit events.
4. `go.uber.org/zap`: A structured logging library used throughout the implementation.

## Configuration
The Kafka sink can be configured using the `config.KafkaSinkConfig` struct, which includes options for:

- Bootstrap servers
- Topic name
- TLS settings
- SASL authentication (SCRAM-SHA-256 or SCRAM-SHA-512)
- Schema registry URL
- Encoding type (Protobuf or Avro)

These configuration options allow for flexible deployment in various Kafka environments, from simple setups to more complex, secure configurations.

In summary, this directory provides a robust, configurable Kafka sink for Flipt's audit logging system, supporting different encoding formats and security configurations while ensuring efficient and reliable delivery of audit events to a Kafka topic.